{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "- Michelle Ma: \n",
    "- Yves Mojica:  \n",
    "- Edgar Seecof: \n",
    "- Travon Williams: \n",
    "- Felix Xie: "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To what extent does first year STEM majors early academic performance predict student dropout at research focused college institutions. Specifically, using students first-year GPA, course completion rates, and credit accumulation as predictors, can we model the probability that a student drops out within one year? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: REPLACE the contents of this cell with your work, including any updates to recover points lost in your proposal feedback"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the data available to us, we predict that there will be a slight correlation between the early academic performance of a student and the likelihood of dropping out of university.  A recurrence of class failure doesn't necessarily mean that a student will inevitably dropout; there are likely other factors that have a greater correlation with early dropout than failing classes in your first year . Students can always catch up, but those who struggle early on will have a harder start to their college career that is more likely to lead to dropping out."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview\n",
    "\n",
    "Data Overview\n",
    "### Dataset #1\n",
    "\n",
    "- Dataset Name: Predict Students’ Dropout and Academic Success Dataset\n",
    "\n",
    "- Link to dataset: https://archive.ics.uci.edu/dataset/697/predict+students%27+dropout+and+academic+success\n",
    "\n",
    "- Number of observations: 4,424\n",
    "- Number of variables: 37\n",
    "\n",
    "#### Relevant variables:\n",
    "\n",
    "- Academic performance and grades\n",
    "\n",
    "- Student background information\n",
    "\n",
    "- Enrollment characteristics\n",
    "\n",
    "- Dropout or academic success labels\n",
    "\n",
    "#### Shortcomings:\n",
    "\n",
    "- Limited demographic diversity\n",
    "\n",
    "- May not generalize beyond the sampled institutions\n",
    "\n",
    "- Some variables may contain missing or inconsistent values\n",
    "\n",
    "\n",
    "#### Description:\n",
    "\n",
    "- This dataset contains student-level academic and demographic information used to predict dropout and academic success. Each row represents an individual student record with performance and background features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset #2\n",
    "\n",
    "### Dataset Name: TEC Student Academic Records Dataset\n",
    "\n",
    "- Link to dataset: https://datahub.tec.mx/file.xhtml?persistentId=doi:10.57687/FK2/PWJRSJ/7QTPBO\n",
    "\n",
    "- Number of observations: (fill in after loading)\n",
    "- Number of variables: (fill in after loading)\n",
    "\n",
    "#### Relevant variables:\n",
    "\n",
    "- Academic performance and grades\n",
    "\n",
    "- Enrollment and course participation\n",
    "\n",
    "- Institutional engagement indicators\n",
    "\n",
    "#### Shortcomings:\n",
    "\n",
    "- Institution-specific structure\n",
    "\n",
    "- Possible missing or incomplete engagement records\n",
    "\n",
    "- Limited time span\n",
    "\n",
    "#### Description:\n",
    "\n",
    "- This dataset includes academic and engagement records from a technological university. It provides insight into student participation and performance across courses.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset #3\n",
    "\n",
    "### Dataset Name: University Dropout Dataset (2022)\n",
    "\n",
    "- Link to dataset: https://zenodo.org/records/17239943\n",
    "\n",
    "- Number of observations: 159,173\n",
    "- Number of variables: 169\n",
    "#### Relevant variables:\n",
    "\n",
    "- Academic performance and grades\n",
    "\n",
    "- Learning management system engagement\n",
    "\n",
    "- Campus activity indicators\n",
    "\n",
    "- Student background information\n",
    "\n",
    "#### Shortcomings:\n",
    "\n",
    "- High missingness in engagement variables\n",
    "\n",
    "- Single-institution focus\n",
    "\n",
    "- Differences in grading systems\n",
    "\n",
    "  \n",
    "\n",
    "#### Description:\n",
    "\n",
    "- This dataset contains anonymized student academic and engagement records used to analyze dropout behavior and academic success.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining the datasets\n",
    "\n",
    "\n",
    "Our three datasets will be used to compare patterns between student dropout and their failure of classes in their first year. The datasets come from different sources and structures, but they share common themes being most importnatly students academic perfomance data. We will standardize relevant variables and zero in on trends across the datasets to find the most consistent predictors that leads to dropouts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "RAW_DATA_DIR = 'data/00-raw/'\n",
    "INT_DATA_DIR = 'data/01-interim/'\n",
    "PROCESSED_DATA_DIR = 'data/02-processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Download Progress:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Downloading predict_students_dropout.zip: 0.00B [00:00, ?B/s]\u001b[A\n",
      "Overall Download Progress:  50%|█████     | 1/2 [00:00<00:00,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: predict_students_dropout.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading university_dropout_2022.zip:   0%|          | 0.00/15.1M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading university_dropout_2022.zip:   0%|          | 11.3k/15.1M [00:00<02:26, 103kB/s]\u001b[A\n",
      "Downloading university_dropout_2022.zip:   0%|          | 36.9k/15.1M [00:00<02:14, 112kB/s]\u001b[A\n",
      "Downloading university_dropout_2022.zip:   1%|          | 94.2k/15.1M [00:00<01:06, 225kB/s]\u001b[A\n",
      "Downloading university_dropout_2022.zip:   1%|▏         | 207k/15.1M [00:00<00:32, 453kB/s] \u001b[A\n",
      "Downloading university_dropout_2022.zip:   3%|▎         | 431k/15.1M [00:00<00:18, 804kB/s]\u001b[A\n",
      "Downloading university_dropout_2022.zip:   6%|▌         | 889k/15.1M [00:00<00:09, 1.51MB/s]\u001b[A\n",
      "Downloading university_dropout_2022.zip:  12%|█▏        | 1.81M/15.1M [00:01<00:04, 2.87MB/s]\u001b[A\n",
      "Downloading university_dropout_2022.zip:  14%|█▍        | 2.09M/15.1M [00:01<00:05, 2.29MB/s]\u001b[A\n",
      "Downloading university_dropout_2022.zip:  25%|██▍       | 3.72M/15.1M [00:01<00:02, 4.96MB/s]\u001b[A\n",
      "Downloading university_dropout_2022.zip:  28%|██▊       | 4.30M/15.1M [00:01<00:02, 4.13MB/s]\u001b[A\n",
      "Downloading university_dropout_2022.zip:  35%|███▍      | 5.27M/15.1M [00:01<00:01, 5.07MB/s]\u001b[A\n",
      "Downloading university_dropout_2022.zip:  43%|████▎     | 6.48M/15.1M [00:01<00:01, 5.77MB/s]\u001b[A\n",
      "Downloading university_dropout_2022.zip:  47%|████▋     | 7.11M/15.1M [00:02<00:01, 5.14MB/s]\u001b[A\n",
      "Downloading university_dropout_2022.zip:  51%|█████     | 7.69M/15.1M [00:02<00:01, 4.64MB/s]\u001b[A\n",
      "Downloading university_dropout_2022.zip:  54%|█████▍    | 8.18M/15.1M [00:02<00:01, 4.14MB/s]\u001b[A\n",
      "Downloading university_dropout_2022.zip:  62%|██████▏   | 9.33M/15.1M [00:02<00:01, 4.97MB/s]\u001b[A\n",
      "Downloading university_dropout_2022.zip:  66%|██████▋   | 10.1M/15.1M [00:02<00:01, 4.85MB/s]\u001b[A\n",
      "Downloading university_dropout_2022.zip:  70%|██████▉   | 10.6M/15.1M [00:02<00:01, 4.34MB/s]\u001b[A\n",
      "Downloading university_dropout_2022.zip:  73%|███████▎  | 11.1M/15.1M [00:03<00:01, 3.99MB/s]\u001b[A\n",
      "Downloading university_dropout_2022.zip:  77%|███████▋  | 11.6M/15.1M [00:03<00:00, 3.78MB/s]\u001b[A\n",
      "Downloading university_dropout_2022.zip:  81%|████████  | 12.2M/15.1M [00:03<00:00, 3.63MB/s]\u001b[A\n",
      "Downloading university_dropout_2022.zip:  84%|████████▎ | 12.6M/15.1M [00:03<00:00, 3.31MB/s]\u001b[A\n",
      "Downloading university_dropout_2022.zip:  87%|████████▋ | 13.1M/15.1M [00:03<00:00, 3.26MB/s]\u001b[A\n",
      "Downloading university_dropout_2022.zip:  89%|████████▉ | 13.5M/15.1M [00:03<00:00, 2.98MB/s]\u001b[A\n",
      "Downloading university_dropout_2022.zip:  92%|█████████▏| 13.9M/15.1M [00:04<00:00, 3.12MB/s]\u001b[A\n",
      "Downloading university_dropout_2022.zip:  95%|█████████▍| 14.3M/15.1M [00:04<00:00, 2.91MB/s]\u001b[A\n",
      "Downloading university_dropout_2022.zip:  97%|█████████▋| 14.6M/15.1M [00:04<00:00, 2.29MB/s]\u001b[A\n",
      "Downloading university_dropout_2022.zip:  99%|█████████▉| 15.0M/15.1M [00:04<00:00, 2.62MB/s]\u001b[A\n",
      "Overall Download Progress: 100%|██████████| 2/2 [00:05<00:00,  2.86s/it]                     \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: university_dropout_2022.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') \n",
    "\n",
    "import get_data \n",
    "\n",
    "datafiles = [\n",
    "    {\n",
    "        'url': 'https://archive.ics.uci.edu/static/public/697/predict+students+dropout+and+academic+success.zip',\n",
    "        'filename': 'predict_students_dropout.zip'\n",
    "    },\n",
    "    { \n",
    "        'url': 'https://zenodo.org/records/17239943/files/dataset_2022_hash.zip?download=1', \n",
    "        'filename':'university_dropout_2022.zip'\n",
    "    } # Decompressed later using pd.read_csv\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Students’ Dropout and Academic Success dataset\n",
    "\n",
    "The Students' Dropout and Academic Success dataset consists of 1 large CSV file containing a table of data from 4424 responses of students, and 36 different variables/questions. This dataset was created to identify students at risk of dropping out early in their academic career. The variables from this table range from normal metrics such as age or gender to more specific ones such as admission grades or frequency of attendance. For our project, we'll mostly just be looking at the variables related to academic performance, but there are a few that might provide interesting information that we'll also keep an eye on. The link to the data set can be found [here](https://archive.ics.uci.edu/dataset/697/predict+students%27+dropout+and+academic+success)\n",
    "\n",
    "The columns from the dataset we'll for sure be looking at will be the curricular units from the first and second semesters, which include (grade averages, units enrolled, credited, evaluated, not evaluated, and approved), as well as the target column. Early academic performance could also be influenced by other factors, such as previous qualifications or admission grades found in the dataset. The dataset contains information on the number of units a student takes in their first year, split into two semesters. The grade averages are the GPA of a specific student in that specific semester, which just measures the academic performance of a student. The GPA is on the Portuguese scale, so their equivalent of a 4.0 GPA would be a 20.0. A bad gpa would be considered anything less than a 14.0 or the equivalent of a 2.0 in the U.S. A proficient GPA would be between 14.0 and 16.0, which is below a 3.0 GPA. Anything above a 16.0 would just be considered a good GPA. The number of units enrolled is just a numerical value that measures how many credit units/hours a student is taking. This data can be compared to the column with the approved credit units, since that column measures the credits a student earns from successfully passing their courses. The number of evaluations a student takes refers to the number of  exams (evaluations) a student takes in a semester. The number of credited curricular units refers to transfer units from previous coursework. There is a  final column called \"target\", which pretty much lists the final status of these students after conducted for the study, categorical data that lists either \"enrolled\", \"graduate\", or \"drop-out\". These 6 main columns provide some information on the early academic performance of a student through GPA and curricular units, which are about 25 to 30 hours of work per unit. \n",
    "- Enrolled: Number of curricular units being taken in a semester\n",
    "- Credited: Number of transfer curricular units from prior courses\n",
    "- Evaluated: Number of exams taken in curricular units in a semester\n",
    "- Not Evaluated: Number of curricular units without any exams/evaluations\n",
    "- Approved: Number of curricular units passed\n",
    "- Target: Status of student, enrolled, graduate, or dropout\n",
    "\n",
    "Additionally, two columns we could also look at would be previous qualifications, which are just integers that tell us the education level before entering university (a continuous integer scale from 0 to 200 is also in the dataset), and the other column is an admission grade, ranging from 0 to 200, which can also influence early academic performance. A poor admission grade would be below 100, a proficient one would be below 150, and anything higher would be considered a good admission grade reflective of their prior experience. These are all very useful metrics, and the dataset is mostly cleaned out and ready to be used and analyzed by us, but there are a few concerns regarding this dataset. One concern is the fact that all the data is taken from Portuguese students, so things like GPA, course units, and even the overall academic system will differ from what we're used to. This might require making some values more readable, such as a Portuguese GPA conversion to the U.S. system. We'll just have to take account of possible differences in how Portuguese higher education varies from the U.S. system. A smaller concern would be the fact that while the dataset is clean, there are a lot of columns with 0 values that we will not be able to use. So while the dataset is tidy, there are plenty of rows that are incomplete. Besides that, this dataset has a lot of information we can use, and any concerns we have with it can be worked around. \n",
    "\n",
    "3. Use the cell below to \n",
    "    1. load the dataset \n",
    "    2. make the dataset tidy or demonstrate that it was already tidy\n",
    "    3. demonstrate the size of the dataset\n",
    "    4. find out how much data is missing, where its missing, and if its missing at random or seems to have any systematic relationships in its missingness\n",
    "    5. find and flag any outliers or suspicious entries\n",
    "    6. clean the data or demonstrate that it was already clean.  You may choose how to deal with missingness (dropna of fillna... how='any' or 'all') and you should justify your choice in some way\n",
    "    7. You will load raw data from `data/00-raw/`, you will (optionally) write intermediate stages of your work to `data/01-interim` and you will write the final fully wrangled version of your data to `data/02-processed`\n",
    "4. Optionally you can also show some summary statistics for variables that you think are important to the project\n",
    "5. Feel free to add more cells here if that's helpful for you\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n",
    "## 3.A LOAD DATASET\n",
    "data1 = pd.read_csv(\n",
    "    f'{RAW_DATA_DIR}predict_students_dropout.zip',\n",
    "    sep=';',\n",
    "    compression='zip' # Webpage download default as .zip\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital status</th>\n",
       "      <th>Application mode</th>\n",
       "      <th>Application order</th>\n",
       "      <th>Course</th>\n",
       "      <th>Daytime/evening attendance\\t</th>\n",
       "      <th>Previous qualification</th>\n",
       "      <th>Previous qualification (grade)</th>\n",
       "      <th>Nacionality</th>\n",
       "      <th>Mother's qualification</th>\n",
       "      <th>Father's qualification</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 2nd sem (credited)</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>9254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9070</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>9773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>8014</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>9991</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>133.1</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>16.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>142.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>14.345000</td>\n",
       "      <td>0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-4.06</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>9254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>119.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-4.06</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>137.0</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>14.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>138.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.51</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Marital status  Application mode  Application order  Course  \\\n",
       "0               1                17                  5     171   \n",
       "1               1                15                  1    9254   \n",
       "2               1                 1                  5    9070   \n",
       "3               1                17                  2    9773   \n",
       "4               2                39                  1    8014   \n",
       "5               2                39                  1    9991   \n",
       "6               1                 1                  1    9500   \n",
       "7               1                18                  4    9254   \n",
       "8               1                 1                  3    9238   \n",
       "9               1                 1                  1    9238   \n",
       "\n",
       "   Daytime/evening attendance\\t  Previous qualification  \\\n",
       "0                             1                       1   \n",
       "1                             1                       1   \n",
       "2                             1                       1   \n",
       "3                             1                       1   \n",
       "4                             0                       1   \n",
       "5                             0                      19   \n",
       "6                             1                       1   \n",
       "7                             1                       1   \n",
       "8                             1                       1   \n",
       "9                             1                       1   \n",
       "\n",
       "   Previous qualification (grade)  Nacionality  Mother's qualification  \\\n",
       "0                           122.0            1                      19   \n",
       "1                           160.0            1                       1   \n",
       "2                           122.0            1                      37   \n",
       "3                           122.0            1                      38   \n",
       "4                           100.0            1                      37   \n",
       "5                           133.1            1                      37   \n",
       "6                           142.0            1                      19   \n",
       "7                           119.0            1                      37   \n",
       "8                           137.0           62                       1   \n",
       "9                           138.0            1                       1   \n",
       "\n",
       "   Father's qualification  ...  Curricular units 2nd sem (credited)  \\\n",
       "0                      12  ...                                    0   \n",
       "1                       3  ...                                    0   \n",
       "2                      37  ...                                    0   \n",
       "3                      37  ...                                    0   \n",
       "4                      38  ...                                    0   \n",
       "5                      37  ...                                    0   \n",
       "6                      38  ...                                    0   \n",
       "7                      37  ...                                    0   \n",
       "8                       1  ...                                    0   \n",
       "9                      19  ...                                    0   \n",
       "\n",
       "   Curricular units 2nd sem (enrolled)  \\\n",
       "0                                    0   \n",
       "1                                    6   \n",
       "2                                    6   \n",
       "3                                    6   \n",
       "4                                    6   \n",
       "5                                    5   \n",
       "6                                    8   \n",
       "7                                    5   \n",
       "8                                    6   \n",
       "9                                    6   \n",
       "\n",
       "   Curricular units 2nd sem (evaluations)  \\\n",
       "0                                       0   \n",
       "1                                       6   \n",
       "2                                       0   \n",
       "3                                      10   \n",
       "4                                       6   \n",
       "5                                      17   \n",
       "6                                       8   \n",
       "7                                       5   \n",
       "8                                       7   \n",
       "9                                      14   \n",
       "\n",
       "   Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "0                                    0                          0.000000   \n",
       "1                                    6                         13.666667   \n",
       "2                                    0                          0.000000   \n",
       "3                                    5                         12.400000   \n",
       "4                                    6                         13.000000   \n",
       "5                                    5                         11.500000   \n",
       "6                                    8                         14.345000   \n",
       "7                                    0                          0.000000   \n",
       "8                                    6                         14.142857   \n",
       "9                                    2                         13.500000   \n",
       "\n",
       "   Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "0                                               0               10.8   \n",
       "1                                               0               13.9   \n",
       "2                                               0               10.8   \n",
       "3                                               0                9.4   \n",
       "4                                               0               13.9   \n",
       "5                                               5               16.2   \n",
       "6                                               0               15.5   \n",
       "7                                               0               15.5   \n",
       "8                                               0               16.2   \n",
       "9                                               0                8.9   \n",
       "\n",
       "   Inflation rate   GDP    Target  \n",
       "0             1.4  1.74   Dropout  \n",
       "1            -0.3  0.79  Graduate  \n",
       "2             1.4  1.74   Dropout  \n",
       "3            -0.8 -3.12  Graduate  \n",
       "4            -0.3  0.79  Graduate  \n",
       "5             0.3 -0.92  Graduate  \n",
       "6             2.8 -4.06  Graduate  \n",
       "7             2.8 -4.06   Dropout  \n",
       "8             0.3 -0.92  Graduate  \n",
       "9             1.4  3.51   Dropout  \n",
       "\n",
       "[10 rows x 37 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 3.B MAKE TIDY OR SHOW TIDY\n",
    "data1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape (rows, columns): (4424, 37)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Marital status                                      int64\n",
       "Application mode                                    int64\n",
       "Application order                                   int64\n",
       "Course                                              int64\n",
       "Daytime/evening attendance\\t                        int64\n",
       "Previous qualification                              int64\n",
       "Previous qualification (grade)                    float64\n",
       "Nacionality                                         int64\n",
       "Mother's qualification                              int64\n",
       "Father's qualification                              int64\n",
       "Mother's occupation                                 int64\n",
       "Father's occupation                                 int64\n",
       "Admission grade                                   float64\n",
       "Displaced                                           int64\n",
       "Educational special needs                           int64\n",
       "Debtor                                              int64\n",
       "Tuition fees up to date                             int64\n",
       "Gender                                              int64\n",
       "Scholarship holder                                  int64\n",
       "Age at enrollment                                   int64\n",
       "International                                       int64\n",
       "Curricular units 1st sem (credited)                 int64\n",
       "Curricular units 1st sem (enrolled)                 int64\n",
       "Curricular units 1st sem (evaluations)              int64\n",
       "Curricular units 1st sem (approved)                 int64\n",
       "Curricular units 1st sem (grade)                  float64\n",
       "Curricular units 1st sem (without evaluations)      int64\n",
       "Curricular units 2nd sem (credited)                 int64\n",
       "Curricular units 2nd sem (enrolled)                 int64\n",
       "Curricular units 2nd sem (evaluations)              int64\n",
       "Curricular units 2nd sem (approved)                 int64\n",
       "Curricular units 2nd sem (grade)                  float64\n",
       "Curricular units 2nd sem (without evaluations)      int64\n",
       "Unemployment rate                                 float64\n",
       "Inflation rate                                    float64\n",
       "GDP                                               float64\n",
       "Target                                             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 3.C DEMONSTRATE SIZE OF DATASET\n",
    "print(\"Dataset shape (rows, columns):\", data1.shape)\n",
    "data1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This data set was already used for more formal projects and has already been cleaned of missing values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 missing values.\n"
     ]
    }
   ],
   "source": [
    "## 3.D FIND OUT HOW MUCH DATA IS MISSING AND WHERE\n",
    "col_missing_count = data1.isnull().sum()\n",
    "total_missing_count = col_missing_count.sum()\n",
    "total_missing_count\n",
    "print(f\"There are {total_missing_count} missing values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers in each column\n",
      "Marital status_outlier                                     505\n",
      "Application mode_outlier                                     0\n",
      "Application order_outlier                                  541\n",
      "Course_outlier                                             442\n",
      "Daytime/evening attendance\\t_outlier                       483\n",
      "Previous qualification_outlier                             707\n",
      "Previous qualification (grade)_outlier                     179\n",
      "Nacionality_outlier                                        110\n",
      "Mother's qualification_outlier                               0\n",
      "Father's qualification_outlier                               0\n",
      "Mother's occupation_outlier                                182\n",
      "Father's occupation_outlier                                177\n",
      "Admission grade_outlier                                     86\n",
      "Displaced_outlier                                            0\n",
      "Educational special needs_outlier                           51\n",
      "Debtor_outlier                                             503\n",
      "Tuition fees up to date_outlier                            528\n",
      "Gender_outlier                                               0\n",
      "Scholarship holder_outlier                                1099\n",
      "Age at enrollment_outlier                                  441\n",
      "International_outlier                                      110\n",
      "Curricular units 1st sem (credited)_outlier                577\n",
      "Curricular units 1st sem (enrolled)_outlier                424\n",
      "Curricular units 1st sem (evaluations)_outlier             158\n",
      "Curricular units 1st sem (approved)_outlier                180\n",
      "Curricular units 1st sem (grade)_outlier                   726\n",
      "Curricular units 1st sem (without evaluations)_outlier     294\n",
      "Curricular units 2nd sem (credited)_outlier                530\n",
      "Curricular units 2nd sem (enrolled)_outlier                369\n",
      "Curricular units 2nd sem (evaluations)_outlier             109\n",
      "Curricular units 2nd sem (approved)_outlier                 44\n",
      "Curricular units 2nd sem (grade)_outlier                   877\n",
      "Curricular units 2nd sem (without evaluations)_outlier     282\n",
      "Unemployment rate_outlier                                    0\n",
      "Inflation rate_outlier                                       0\n",
      "GDP_outlier                                                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## 3.E FIND AND FLAG ANY OUTLIERS OR SUS ENTRIES\n",
    "numeric_cols = data1.select_dtypes(include = ['number']).columns\n",
    "outliers = pd.DataFrame(index = data1.index)\n",
    "## iterate accross all numeric columns and find outliers and store in outliers df\n",
    "for col in numeric_cols:\n",
    "    ##https://stackoverflow.com/questions/23228244/how-do-you-find-the-iqr-in-numpy\n",
    "    q75, q25 = np.nanpercentile(data1[col], [75, 25])\n",
    "    iqr = q75 - q25\n",
    "    lower_bound = q25 - 1.5 * iqr\n",
    "    upper_bound = q75 + 1.5 * iqr\n",
    "    outliers[f'{col}_outlier'] = (data1[col] < lower_bound) | (data1[col] > upper_bound)\n",
    "\n",
    "print('Number of outliers in each column')\n",
    "print(outliers.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This data is already very clean, no missing values or ridiculous outliers, the only thing that we may have to change is the data types being used for certain variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values\n"
     ]
    }
   ],
   "source": [
    "## 3.F CLEAN THE DATA\n",
    "if data1.isna().sum().sum() == 0:\n",
    "    print('No missing values')\n",
    "else: \n",
    "    print(f'There are {data1.isna().sum().sum()} missin values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.G MOVE TO PROCESSED\n",
    "data1_clean = data1.copy()\n",
    "processed_path = os.path.join(PROCESSED_DATA_DIR, 'predict_students_dropout_clean.csv')\n",
    "data1_clean.to_csv(processed_path, index=False, sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital status</th>\n",
       "      <th>Application mode</th>\n",
       "      <th>Application order</th>\n",
       "      <th>Course</th>\n",
       "      <th>Daytime/evening attendance\\t</th>\n",
       "      <th>Previous qualification</th>\n",
       "      <th>Previous qualification (grade)</th>\n",
       "      <th>Nacionality</th>\n",
       "      <th>Mother's qualification</th>\n",
       "      <th>Father's qualification</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 1st sem (without evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (credited)</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.178571</td>\n",
       "      <td>18.669078</td>\n",
       "      <td>1.727848</td>\n",
       "      <td>8856.642631</td>\n",
       "      <td>0.890823</td>\n",
       "      <td>4.577758</td>\n",
       "      <td>132.613314</td>\n",
       "      <td>1.873192</td>\n",
       "      <td>19.561935</td>\n",
       "      <td>22.275316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137658</td>\n",
       "      <td>0.541817</td>\n",
       "      <td>6.232143</td>\n",
       "      <td>8.063291</td>\n",
       "      <td>4.435805</td>\n",
       "      <td>10.230206</td>\n",
       "      <td>0.150316</td>\n",
       "      <td>11.566139</td>\n",
       "      <td>1.228029</td>\n",
       "      <td>0.001969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.605747</td>\n",
       "      <td>17.484682</td>\n",
       "      <td>1.313793</td>\n",
       "      <td>2063.566416</td>\n",
       "      <td>0.311897</td>\n",
       "      <td>10.216592</td>\n",
       "      <td>13.188332</td>\n",
       "      <td>6.914514</td>\n",
       "      <td>15.603186</td>\n",
       "      <td>15.343108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.690880</td>\n",
       "      <td>1.918546</td>\n",
       "      <td>2.195951</td>\n",
       "      <td>3.947951</td>\n",
       "      <td>3.014764</td>\n",
       "      <td>5.210808</td>\n",
       "      <td>0.753774</td>\n",
       "      <td>2.663850</td>\n",
       "      <td>1.382711</td>\n",
       "      <td>2.269935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>-4.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9085.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>-1.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9238.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>133.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9556.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.900000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>1.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9991.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>18.571429</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>16.200000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>3.510000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Marital status  Application mode  Application order       Course  \\\n",
       "count     4424.000000       4424.000000        4424.000000  4424.000000   \n",
       "mean         1.178571         18.669078           1.727848  8856.642631   \n",
       "std          0.605747         17.484682           1.313793  2063.566416   \n",
       "min          1.000000          1.000000           0.000000    33.000000   \n",
       "25%          1.000000          1.000000           1.000000  9085.000000   \n",
       "50%          1.000000         17.000000           1.000000  9238.000000   \n",
       "75%          1.000000         39.000000           2.000000  9556.000000   \n",
       "max          6.000000         57.000000           9.000000  9991.000000   \n",
       "\n",
       "       Daytime/evening attendance\\t  Previous qualification  \\\n",
       "count                   4424.000000             4424.000000   \n",
       "mean                       0.890823                4.577758   \n",
       "std                        0.311897               10.216592   \n",
       "min                        0.000000                1.000000   \n",
       "25%                        1.000000                1.000000   \n",
       "50%                        1.000000                1.000000   \n",
       "75%                        1.000000                1.000000   \n",
       "max                        1.000000               43.000000   \n",
       "\n",
       "       Previous qualification (grade)  Nacionality  Mother's qualification  \\\n",
       "count                     4424.000000  4424.000000             4424.000000   \n",
       "mean                       132.613314     1.873192               19.561935   \n",
       "std                         13.188332     6.914514               15.603186   \n",
       "min                         95.000000     1.000000                1.000000   \n",
       "25%                        125.000000     1.000000                2.000000   \n",
       "50%                        133.100000     1.000000               19.000000   \n",
       "75%                        140.000000     1.000000               37.000000   \n",
       "max                        190.000000   109.000000               44.000000   \n",
       "\n",
       "       Father's qualification  ...  \\\n",
       "count             4424.000000  ...   \n",
       "mean                22.275316  ...   \n",
       "std                 15.343108  ...   \n",
       "min                  1.000000  ...   \n",
       "25%                  3.000000  ...   \n",
       "50%                 19.000000  ...   \n",
       "75%                 37.000000  ...   \n",
       "max                 44.000000  ...   \n",
       "\n",
       "       Curricular units 1st sem (without evaluations)  \\\n",
       "count                                     4424.000000   \n",
       "mean                                         0.137658   \n",
       "std                                          0.690880   \n",
       "min                                          0.000000   \n",
       "25%                                          0.000000   \n",
       "50%                                          0.000000   \n",
       "75%                                          0.000000   \n",
       "max                                         12.000000   \n",
       "\n",
       "       Curricular units 2nd sem (credited)  \\\n",
       "count                          4424.000000   \n",
       "mean                              0.541817   \n",
       "std                               1.918546   \n",
       "min                               0.000000   \n",
       "25%                               0.000000   \n",
       "50%                               0.000000   \n",
       "75%                               0.000000   \n",
       "max                              19.000000   \n",
       "\n",
       "       Curricular units 2nd sem (enrolled)  \\\n",
       "count                          4424.000000   \n",
       "mean                              6.232143   \n",
       "std                               2.195951   \n",
       "min                               0.000000   \n",
       "25%                               5.000000   \n",
       "50%                               6.000000   \n",
       "75%                               7.000000   \n",
       "max                              23.000000   \n",
       "\n",
       "       Curricular units 2nd sem (evaluations)  \\\n",
       "count                             4424.000000   \n",
       "mean                                 8.063291   \n",
       "std                                  3.947951   \n",
       "min                                  0.000000   \n",
       "25%                                  6.000000   \n",
       "50%                                  8.000000   \n",
       "75%                                 10.000000   \n",
       "max                                 33.000000   \n",
       "\n",
       "       Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "count                          4424.000000                       4424.000000   \n",
       "mean                              4.435805                         10.230206   \n",
       "std                               3.014764                          5.210808   \n",
       "min                               0.000000                          0.000000   \n",
       "25%                               2.000000                         10.750000   \n",
       "50%                               5.000000                         12.200000   \n",
       "75%                               6.000000                         13.333333   \n",
       "max                              20.000000                         18.571429   \n",
       "\n",
       "       Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "count                                     4424.000000        4424.000000   \n",
       "mean                                         0.150316          11.566139   \n",
       "std                                          0.753774           2.663850   \n",
       "min                                          0.000000           7.600000   \n",
       "25%                                          0.000000           9.400000   \n",
       "50%                                          0.000000          11.100000   \n",
       "75%                                          0.000000          13.900000   \n",
       "max                                         12.000000          16.200000   \n",
       "\n",
       "       Inflation rate          GDP  \n",
       "count     4424.000000  4424.000000  \n",
       "mean         1.228029     0.001969  \n",
       "std          1.382711     2.269935  \n",
       "min         -0.800000    -4.060000  \n",
       "25%          0.300000    -1.700000  \n",
       "50%          1.400000     0.320000  \n",
       "75%          2.600000     1.790000  \n",
       "max          3.700000     3.510000  \n",
       "\n",
       "[8 rows x 36 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 4. SUMMARY STATISTICS\n",
    "data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Previous qualification (grade)  Admission grade  \\\n",
      "0                               2.44            2.546   \n",
      "1                               3.20            2.850   \n",
      "2                               2.44            2.496   \n",
      "3                               2.44            2.392   \n",
      "4                               2.00            2.830   \n",
      "...                              ...              ...   \n",
      "4419                            2.50            2.444   \n",
      "4420                            2.40            2.380   \n",
      "4421                            3.08            2.990   \n",
      "4422                            3.60            3.076   \n",
      "4423                            3.04            3.040   \n",
      "\n",
      "      Curricular units 1st sem (grade)  Curricular units 2nd sem (grade)  \n",
      "0                             0.000000                          0.000000  \n",
      "1                             0.280000                          0.273333  \n",
      "2                             0.000000                          0.000000  \n",
      "3                             0.268571                          0.248000  \n",
      "4                             0.246667                          0.260000  \n",
      "...                                ...                               ...  \n",
      "4419                          0.272000                          0.253333  \n",
      "4420                          0.240000                          0.220000  \n",
      "4421                          0.298250                          0.270000  \n",
      "4422                          0.276000                          0.240000  \n",
      "4423                          0.233333                          0.260000  \n",
      "\n",
      "[4424 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "## 5. TRANSFORMING PORTUGESE GRADING SCALE TO 4.0\n",
    "max_port = 200.0\n",
    "min_port = 0.0\n",
    "max_usa = 4.0\n",
    "\n",
    "grade_cols = [\n",
    "    'Previous qualification (grade)',\n",
    "    'Admission grade',\n",
    "    'Curricular units 1st sem (grade)',\n",
    "    'Curricular units 2nd sem (grade)'\n",
    "]\n",
    "\n",
    "for col in grade_cols:\n",
    "    data1[col] = (data1[col] / max_port) * max_usa\n",
    "\n",
    "print(data1[grade_cols])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### University Student Dropout Dataset\n",
    "\n",
    "The University Student Dropout dataset is organized as yearly CSV files named dataset_{year}.csv, with each row corresponding to a student-course enrollment for that academic year. Each file integrates data from four sources: students, programs, courses, and digital logs, and also groups variables into six thematic categories: context, admission pathways, socio-economic and demographic background, academic data, digital logs, and Wi-Fi access. Contextual attributes include anonymized identifiers for students, courses, academic programs, and campuses, as well as the academic year and group IDs, capturing where and how each student is enrolled. Admission pathway variables describe how the student entered the university, including year of enrollment, type of admission, entry exam grades (scaled to 10 or 14), and program selection preference. Socioeconomic and demographic variables capture parental education, student dedication to studies, and whether the student had to move provinces to attend university, providing insight into economic or social challenges that might affect retention.\n",
    "\n",
    "Academic data is the most detailed category, including grades, credits enrolled and earned across multiple years, semester performance, adjustments for credit recognition, internships, activities, and overall progress toward degree completion. Metrics like cumulative GPA, credits passed per semester, and credit completion rates across previous years allow for longitudinal assessment of academic success and dropout risk. Digital logs track Learning Management System (LMS) site engagement monthly, including number of visits, events, assignment and test submissions, total minutes spent online, and usage of course resources. For 2021 and 2022, Wi-Fi access records provide an additional proxy for on-campus presence, recording the number of days each student accessed the university network per month. All variables are anonymized using hash codes, and numerical metrics such as grades are scaled (e.g., 0–10 or 0–14 for entry exams), while credit counts are in academic credit units. LMS and Wi-Fi activity metrics are counts of actions, logins, or days.\n",
    "\n",
    "While these metrics provide valuable insights, several concerns about the dataset should be noted. It is drawn from a single Spanish technological university, which limits generalizability to other fields or institutions, particularly in humanities or social sciences. Early dropouts may be underrepresented, and some variables, like parental education, employment, student dedication, may be self-reported and incomplete. Engagement measures may also reflect infrastructure availability or device usage rather than actual participation. Finally, identifiers are anonymized, which may reduce the precision of longitudinal tracking, and the data does not include periods affected by the COVID-19 pandemic, meaning it may not capture disruptions caused by virtual or hybrid learning environments. Despite these limitations, the dataset provides a detailed framework for studying factors influencing student retention and academic success.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1409/936537943.py:4: DtypeWarning: Columns (48,57,64,65,164) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data2 = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n",
    "\n",
    "# A - Load the Dataset (Just the 2022 Subset for now - it is quite large)\n",
    "data2 = pd.read_csv(\n",
    "    f'{RAW_DATA_DIR}university_dropout_2022.zip',\n",
    "    sep=';',\n",
    "    compression='zip' # Webpage download default as .zip\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the description of the dataset from the source on Zemodo, the dataset has been thouroughly tidied up, which is demontrated below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n",
      "==================================================\n",
      "Index(['dni_hash', 'tit_hash', 'asi_hash', 'anyo_ingreso', 'tipo_ingreso',\n",
      "       'nota10_hash', 'nota14_hash', 'campus_hash', 'estudios_p_hash',\n",
      "       'estudios_m_hash',\n",
      "       ...\n",
      "       'n_resource_days_2023_6', 'pft_events_2023_7', 'pft_days_logged_2023_7',\n",
      "       'pft_visits_2023_7', 'pft_assignment_submissions_2023_7',\n",
      "       'pft_test_submissions_2023_7', 'pft_total_minutes_2023_7',\n",
      "       'n_wifi_days_2023_7', 'resource_events_2023_7',\n",
      "       'n_resource_days_2023_7'],\n",
      "      dtype='object', length=169)\n",
      "==================================================\n",
      "dni_hash                       object\n",
      "tit_hash                       object\n",
      "asi_hash                       object\n",
      "anyo_ingreso                   object\n",
      "tipo_ingreso                   object\n",
      "                                ...  \n",
      "pft_test_submissions_2023_7    object\n",
      "pft_total_minutes_2023_7       object\n",
      "n_wifi_days_2023_7             object\n",
      "resource_events_2023_7         object\n",
      "n_resource_days_2023_7         object\n",
      "Length: 169, dtype: object\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dni_hash</th>\n",
       "      <th>tit_hash</th>\n",
       "      <th>asi_hash</th>\n",
       "      <th>anyo_ingreso</th>\n",
       "      <th>tipo_ingreso</th>\n",
       "      <th>nota10_hash</th>\n",
       "      <th>nota14_hash</th>\n",
       "      <th>campus_hash</th>\n",
       "      <th>estudios_p_hash</th>\n",
       "      <th>estudios_m_hash</th>\n",
       "      <th>...</th>\n",
       "      <th>n_resource_days_2023_6</th>\n",
       "      <th>pft_events_2023_7</th>\n",
       "      <th>pft_days_logged_2023_7</th>\n",
       "      <th>pft_visits_2023_7</th>\n",
       "      <th>pft_assignment_submissions_2023_7</th>\n",
       "      <th>pft_test_submissions_2023_7</th>\n",
       "      <th>pft_total_minutes_2023_7</th>\n",
       "      <th>n_wifi_days_2023_7</th>\n",
       "      <th>resource_events_2023_7</th>\n",
       "      <th>n_resource_days_2023_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>319636fc9270</td>\n",
       "      <td>620c9c332101</td>\n",
       "      <td>4596fcf257c4</td>\n",
       "      <td>2012,0</td>\n",
       "      <td>NAP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9,456</td>\n",
       "      <td>e4f95d56d90df35e</td>\n",
       "      <td>F</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>319636fc9270</td>\n",
       "      <td>620c9c332101</td>\n",
       "      <td>81f4b5a1d0a8</td>\n",
       "      <td>2012,0</td>\n",
       "      <td>NAP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9,456</td>\n",
       "      <td>e4f95d56d90df35e</td>\n",
       "      <td>F</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>319636fc9270</td>\n",
       "      <td>620c9c332101</td>\n",
       "      <td>442fcac005ed</td>\n",
       "      <td>2012,0</td>\n",
       "      <td>NAP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9,456</td>\n",
       "      <td>e4f95d56d90df35e</td>\n",
       "      <td>F</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>319636fc9270</td>\n",
       "      <td>620c9c332101</td>\n",
       "      <td>3dc87ab71825</td>\n",
       "      <td>2012,0</td>\n",
       "      <td>NAP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9,456</td>\n",
       "      <td>e4f95d56d90df35e</td>\n",
       "      <td>F</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>319636fc9270</td>\n",
       "      <td>620c9c332101</td>\n",
       "      <td>677c622c0bfb</td>\n",
       "      <td>2012,0</td>\n",
       "      <td>NAP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9,456</td>\n",
       "      <td>e4f95d56d90df35e</td>\n",
       "      <td>F</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>319636fc9270</td>\n",
       "      <td>620c9c332101</td>\n",
       "      <td>2344965e8b89</td>\n",
       "      <td>2012,0</td>\n",
       "      <td>NAP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9,456</td>\n",
       "      <td>e4f95d56d90df35e</td>\n",
       "      <td>F</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>319636fc9270</td>\n",
       "      <td>620c9c332101</td>\n",
       "      <td>5f52e54c6a9c</td>\n",
       "      <td>2012,0</td>\n",
       "      <td>NAP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9,456</td>\n",
       "      <td>e4f95d56d90df35e</td>\n",
       "      <td>F</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>319636fc9270</td>\n",
       "      <td>620c9c332101</td>\n",
       "      <td>8b8b029f1142</td>\n",
       "      <td>2012,0</td>\n",
       "      <td>NAP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9,456</td>\n",
       "      <td>e4f95d56d90df35e</td>\n",
       "      <td>F</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>319636fc9270</td>\n",
       "      <td>620c9c332101</td>\n",
       "      <td>705d739be21c</td>\n",
       "      <td>2012,0</td>\n",
       "      <td>NAP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9,456</td>\n",
       "      <td>e4f95d56d90df35e</td>\n",
       "      <td>F</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>319636fc9270</td>\n",
       "      <td>620c9c332101</td>\n",
       "      <td>696d9363dc5a</td>\n",
       "      <td>2012,0</td>\n",
       "      <td>NAP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9,456</td>\n",
       "      <td>e4f95d56d90df35e</td>\n",
       "      <td>F</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 169 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dni_hash      tit_hash      asi_hash anyo_ingreso tipo_ingreso  \\\n",
       "0  319636fc9270  620c9c332101  4596fcf257c4       2012,0          NAP   \n",
       "1  319636fc9270  620c9c332101  81f4b5a1d0a8       2012,0          NAP   \n",
       "2  319636fc9270  620c9c332101  442fcac005ed       2012,0          NAP   \n",
       "3  319636fc9270  620c9c332101  3dc87ab71825       2012,0          NAP   \n",
       "4  319636fc9270  620c9c332101  677c622c0bfb       2012,0          NAP   \n",
       "5  319636fc9270  620c9c332101  2344965e8b89       2012,0          NAP   \n",
       "6  319636fc9270  620c9c332101  5f52e54c6a9c       2012,0          NAP   \n",
       "7  319636fc9270  620c9c332101  8b8b029f1142       2012,0          NAP   \n",
       "8  319636fc9270  620c9c332101  705d739be21c       2012,0          NAP   \n",
       "9  319636fc9270  620c9c332101  696d9363dc5a       2012,0          NAP   \n",
       "\n",
       "  nota10_hash nota14_hash       campus_hash estudios_p_hash estudios_m_hash  \\\n",
       "0         NaN       9,456  e4f95d56d90df35e               F               L   \n",
       "1         NaN       9,456  e4f95d56d90df35e               F               L   \n",
       "2         NaN       9,456  e4f95d56d90df35e               F               L   \n",
       "3         NaN       9,456  e4f95d56d90df35e               F               L   \n",
       "4         NaN       9,456  e4f95d56d90df35e               F               L   \n",
       "5         NaN       9,456  e4f95d56d90df35e               F               L   \n",
       "6         NaN       9,456  e4f95d56d90df35e               F               L   \n",
       "7         NaN       9,456  e4f95d56d90df35e               F               L   \n",
       "8         NaN       9,456  e4f95d56d90df35e               F               L   \n",
       "9         NaN       9,456  e4f95d56d90df35e               F               L   \n",
       "\n",
       "   ... n_resource_days_2023_6 pft_events_2023_7 pft_days_logged_2023_7  \\\n",
       "0  ...                    NaN               NaN                    NaN   \n",
       "1  ...                    NaN               NaN                    NaN   \n",
       "2  ...                    NaN               NaN                    NaN   \n",
       "3  ...                    NaN               NaN                    NaN   \n",
       "4  ...                    NaN               NaN                    NaN   \n",
       "5  ...                    NaN               NaN                    NaN   \n",
       "6  ...                    NaN               NaN                    NaN   \n",
       "7  ...                    NaN               NaN                    NaN   \n",
       "8  ...                    NaN               NaN                    NaN   \n",
       "9  ...                    NaN               NaN                    NaN   \n",
       "\n",
       "  pft_visits_2023_7 pft_assignment_submissions_2023_7  \\\n",
       "0               NaN                               NaN   \n",
       "1               NaN                               NaN   \n",
       "2               NaN                               NaN   \n",
       "3               NaN                               NaN   \n",
       "4               NaN                               NaN   \n",
       "5               NaN                               NaN   \n",
       "6               NaN                               NaN   \n",
       "7               NaN                               NaN   \n",
       "8               NaN                               NaN   \n",
       "9               NaN                               NaN   \n",
       "\n",
       "   pft_test_submissions_2023_7 pft_total_minutes_2023_7 n_wifi_days_2023_7  \\\n",
       "0                          NaN                      NaN                NaN   \n",
       "1                          NaN                      NaN                NaN   \n",
       "2                          NaN                      NaN                NaN   \n",
       "3                          NaN                      NaN                NaN   \n",
       "4                          NaN                      NaN                NaN   \n",
       "5                          NaN                      NaN                NaN   \n",
       "6                          NaN                      NaN                NaN   \n",
       "7                          NaN                      NaN                NaN   \n",
       "8                          NaN                      NaN                NaN   \n",
       "9                          NaN                      NaN                NaN   \n",
       "\n",
       "  resource_events_2023_7 n_resource_days_2023_7  \n",
       "0                    NaN                    NaN  \n",
       "1                    NaN                    NaN  \n",
       "2                    NaN                    NaN  \n",
       "3                    NaN                    NaN  \n",
       "4                    NaN                    NaN  \n",
       "5                    NaN                    NaN  \n",
       "6                    NaN                    NaN  \n",
       "7                    NaN                    NaN  \n",
       "8                    NaN                    NaN  \n",
       "9                    NaN                    NaN  \n",
       "\n",
       "[10 rows x 169 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B - Tidiness\n",
    "\n",
    "# Show that each row is a single observation by cross checking duplicates against the identifiers for student, course, and degree hashes\n",
    "duplicates = data2.duplicated(subset=['dni_hash', 'asi_hash', 'anyo_ingreso'])\n",
    "print(\"Number of duplicate rows:\", duplicates.sum())\n",
    "\n",
    "\n",
    "# Show that columns are aptly named\n",
    "print('='*50)\n",
    "print(data2.columns)\n",
    "print('='*50)\n",
    "print(data2.dtypes) # note that for now, dtypes are often objects because pandas interprets the comma usage in certain numbers as a string most likely\n",
    "\n",
    "# Show a preview of what the data looks like, demonstrating that columns are properly named, there are no overlapping values, and columns are generally meaningful\n",
    "print('='*50)\n",
    "data2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape (rows, columns): (159173, 169)\n",
      "Number of observations of student-course-year (rows): 159173\n",
      "Number of variables (columns): 169\n"
     ]
    }
   ],
   "source": [
    "# C - Size of Dataset\n",
    "print(\"Dataset shape (rows, columns):\", data2.shape)\n",
    "print(\"Number of observations of student-course-year (rows):\", data2.shape[0])\n",
    "print(\"Number of variables (columns):\", data2.shape[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As also mentioned in the paper connected to this dataset, there is a high systematic relationship in the missingness of much of the data, as well as a large portion of columns that have a lot of missing data. This is demonstrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pft_test_submissions_2023_7</th>\n",
       "      <td>159148</td>\n",
       "      <td>99.984294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pft_assignment_submissions_2023_7</th>\n",
       "      <td>158800</td>\n",
       "      <td>99.765664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es_retitulado</th>\n",
       "      <td>158630</td>\n",
       "      <td>99.658862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total1</th>\n",
       "      <td>157656</td>\n",
       "      <td>99.046949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es_adaptado</th>\n",
       "      <td>156916</td>\n",
       "      <td>98.582046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rendimiento_cuat_a</th>\n",
       "      <td>12207</td>\n",
       "      <td>7.669014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rendimiento_cuat_b</th>\n",
       "      <td>9051</td>\n",
       "      <td>5.686266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rendimiento_total</th>\n",
       "      <td>8819</td>\n",
       "      <td>5.540513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>estudios_m_hash</th>\n",
       "      <td>918</td>\n",
       "      <td>0.576731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>estudios_p_hash</th>\n",
       "      <td>918</td>\n",
       "      <td>0.576731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   missing_count  missing_pct\n",
       "pft_test_submissions_2023_7               159148    99.984294\n",
       "pft_assignment_submissions_2023_7         158800    99.765664\n",
       "es_retitulado                             158630    99.658862\n",
       "total1                                    157656    99.046949\n",
       "es_adaptado                               156916    98.582046\n",
       "...                                          ...          ...\n",
       "rendimiento_cuat_a                         12207     7.669014\n",
       "rendimiento_cuat_b                          9051     5.686266\n",
       "rendimiento_total                           8819     5.540513\n",
       "estudios_m_hash                              918     0.576731\n",
       "estudios_p_hash                              918     0.576731\n",
       "\n",
       "[124 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# D - Missing Data Exploration\n",
    "# Basic exploratory analysis on the missing data as porportions and counts\n",
    "missing_counts = data2.isnull().sum()\n",
    "missing_percent = (missing_counts / len(data2)) * 100\n",
    "\n",
    "missing_df = pd.concat([missing_counts, missing_percent], axis=1)\n",
    "missing_df.columns = ['missing_count', 'missing_pct']\n",
    "\n",
    "missing_df = missing_df[missing_df['missing_count'] > 0].sort_values(by='missing_pct', ascending=False)\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "campus_hash\n",
       "1398b376fdcce25c    88.458559\n",
       "297c138806bdb5dd    87.812500\n",
       "9103a6c82e355433    85.704161\n",
       "3ca0e4af1c44f084    84.429455\n",
       "7b778e4c1d1f33c9    83.958427\n",
       "0f01a84bff1b2bf4    82.044018\n",
       "60f19cd67252161d    79.815005\n",
       "85ff657216cc9b54    79.775281\n",
       "1a9d786be0ff0bfe    79.341426\n",
       "6781b441c78d2643    78.329399\n",
       "48c6e3d042649ef6    77.824773\n",
       "234001f5d5f1eca4    77.424844\n",
       "f9418773503e50b6    77.080491\n",
       "47cfe5eb8ada0e74    76.700434\n",
       "79df3742da86cfd4    76.659119\n",
       "40f5b57b09f073ed    76.653696\n",
       "86348ea0bf50ebf0    75.927487\n",
       "4e808094851fc2ea    75.469381\n",
       "16a36e86f6fed5d4    75.291622\n",
       "e984139bcc2c5043    75.257732\n",
       "f32b702fba23083f    74.931880\n",
       "5d9d4510699dac58    74.718222\n",
       "911ac1b13dac6fe9    73.259053\n",
       "ddf9288fd8062579    72.413793\n",
       "0672d49fe5a7035e    72.110665\n",
       "eb074cd8374ba297    71.810089\n",
       "f2a369a3b17169d7    71.753555\n",
       "52025890fa603dbc    70.521364\n",
       "2f4c06aba0f9a393    70.130678\n",
       "0448d563bf72277a    70.024096\n",
       "8138689887e6817e    68.799798\n",
       "c8361f9b468e68c8    65.359477\n",
       "e4f95d56d90df35e    64.516339\n",
       "f01a95a004153cb8    63.482414\n",
       "474ffa8c8cb7e88e    63.478261\n",
       "e176f557f5261788    62.251149\n",
       "5abe6ed555720a3e    61.641221\n",
       "8b336cdf52ac9b75    59.274194\n",
       "dae96fc0046a5ae1    52.682927\n",
       "bc5d84bed7dee3e1    38.461538\n",
       "Name: n_wifi_days_2023_7, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# D - Missing Data Exploration\n",
    "# A deeper dive into why some data is missing in the way it is\n",
    "# Let us take a look at the missing wifi monitoring usage by campus\n",
    "data2.groupby('campus_hash')['n_wifi_days_2023_7'] \\\n",
    "     .apply(lambda x: x.isnull().mean()*100) \\\n",
    "     .sort_values(ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This clearly demonstrates that some campuses such as `bc5d84bed7dee3e1` have a very comparitively low missing percentage (38%) of their students' wifi utilization, while others, like `1398b376fdcce25c` have a very high missing percentage, around 88%. This clearly shows a systematic disparity in certain campus's ability to report such data. While every inconsistency cannot be described due to the sheer size of this dataset, this small subsample shows how there is a large systematic reason for certain data being missing. This is explored in a little more depth in the accompanying paper, but on a theoretical basis, because this dataset was compiled from various databases and resources and then homogenized, inconsistencies are bound to show. Furthermore, certain courses may be more open to utilizing LMS tools or adopting digital platforms for their education, resulting in systematic missingness in the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outlier Discovery\n",
    "\n",
    "The accompanying paper describes that during the data anonymization of students, suspicious variables were dealt with to protect anonymity. For example, if a certain aggregation of variables could identify a student, this was deleted. Furthermore duplicate entries were deleted. Furthermore, a general check to ensure data types remained consistent and that value ranges for data was well within the expected distribution accross datasets was conducted. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning\n",
    "\n",
    "This dataset features a high rate of missingness. As such, the general rule for now that we chose to go with was to delete any columns with a high threshold of missingness. In this case, we chose to drop the columns with more than 90% overall missingness (this means dropping around 30 columns), as even if this data may be useful, the sheer proportion of missing data would make it less impactful. While agressive, this will help us narrow down our scope for our final project. A test also revealed that attempting a super agressive drop of all rows with any sort of missing data would cut the dataset to only 162 entries, so this is also not used. However, entries with all NA entries were deleted. Another notable feature is that the csv was ';' deliminated and utilized commas as decimals, which is quite typical of much of Europe. As such, numbers are cleaned into decimal format and converted to float/int. \n",
    "\n",
    "For specific column-based adjustments, a few rules were established to deal with missingness:\n",
    "\n",
    "1) Leave identifying hashes alone\n",
    "2) Leave demographic/enrollment data alone\n",
    "3) Fill credit/coursework work columns as 0 for NA entries\n",
    "4) Fill activity/practical work columns as 0 for NA entries\n",
    "5) Fill LMS/Wifi/Digital Engagement columns as 0 for NA entries\n",
    "\n",
    "This was done because demographics, enrollement data, and identifying hashes being empty are likely a result of truely missing data. However, the other categories can be attributed to simply the absence of the student doing said column. For example, no entry for credits enrolled for a specific semester and for a specific courses may just mean that the student didn't take that course. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dni_hash</th>\n",
       "      <th>tit_hash</th>\n",
       "      <th>asi_hash</th>\n",
       "      <th>anyo_ingreso</th>\n",
       "      <th>tipo_ingreso</th>\n",
       "      <th>nota10_hash</th>\n",
       "      <th>nota14_hash</th>\n",
       "      <th>campus_hash</th>\n",
       "      <th>estudios_p_hash</th>\n",
       "      <th>estudios_m_hash</th>\n",
       "      <th>...</th>\n",
       "      <th>resource_events_2023_5</th>\n",
       "      <th>n_resource_days_2023_5</th>\n",
       "      <th>pft_events_2023_6</th>\n",
       "      <th>pft_days_logged_2023_6</th>\n",
       "      <th>pft_visits_2023_6</th>\n",
       "      <th>pft_total_minutes_2023_6</th>\n",
       "      <th>n_wifi_days_2023_6</th>\n",
       "      <th>resource_events_2023_6</th>\n",
       "      <th>n_resource_days_2023_6</th>\n",
       "      <th>n_wifi_days_2023_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>319636fc9270</td>\n",
       "      <td>620c9c332101</td>\n",
       "      <td>4596fcf257c4</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>NAP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.456</td>\n",
       "      <td>e4f95d56d90df35e</td>\n",
       "      <td>F</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>319636fc9270</td>\n",
       "      <td>620c9c332101</td>\n",
       "      <td>81f4b5a1d0a8</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>NAP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.456</td>\n",
       "      <td>e4f95d56d90df35e</td>\n",
       "      <td>F</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>319636fc9270</td>\n",
       "      <td>620c9c332101</td>\n",
       "      <td>442fcac005ed</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>NAP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.456</td>\n",
       "      <td>e4f95d56d90df35e</td>\n",
       "      <td>F</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>319636fc9270</td>\n",
       "      <td>620c9c332101</td>\n",
       "      <td>3dc87ab71825</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>NAP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.456</td>\n",
       "      <td>e4f95d56d90df35e</td>\n",
       "      <td>F</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>319636fc9270</td>\n",
       "      <td>620c9c332101</td>\n",
       "      <td>677c622c0bfb</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>NAP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.456</td>\n",
       "      <td>e4f95d56d90df35e</td>\n",
       "      <td>F</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dni_hash      tit_hash      asi_hash  anyo_ingreso tipo_ingreso  \\\n",
       "0  319636fc9270  620c9c332101  4596fcf257c4        2012.0          NAP   \n",
       "1  319636fc9270  620c9c332101  81f4b5a1d0a8        2012.0          NAP   \n",
       "2  319636fc9270  620c9c332101  442fcac005ed        2012.0          NAP   \n",
       "3  319636fc9270  620c9c332101  3dc87ab71825        2012.0          NAP   \n",
       "4  319636fc9270  620c9c332101  677c622c0bfb        2012.0          NAP   \n",
       "\n",
       "   nota10_hash  nota14_hash       campus_hash estudios_p_hash estudios_m_hash  \\\n",
       "0          NaN        9.456  e4f95d56d90df35e               F               L   \n",
       "1          NaN        9.456  e4f95d56d90df35e               F               L   \n",
       "2          NaN        9.456  e4f95d56d90df35e               F               L   \n",
       "3          NaN        9.456  e4f95d56d90df35e               F               L   \n",
       "4          NaN        9.456  e4f95d56d90df35e               F               L   \n",
       "\n",
       "   ... resource_events_2023_5 n_resource_days_2023_5 pft_events_2023_6  \\\n",
       "0  ...                    0.0                    0.0               0.0   \n",
       "1  ...                    0.0                    0.0               0.0   \n",
       "2  ...                    0.0                    0.0               0.0   \n",
       "3  ...                    0.0                    0.0               0.0   \n",
       "4  ...                    0.0                    0.0               0.0   \n",
       "\n",
       "   pft_days_logged_2023_6 pft_visits_2023_6  pft_total_minutes_2023_6  \\\n",
       "0                     0.0               0.0                       0.0   \n",
       "1                     0.0               0.0                       0.0   \n",
       "2                     0.0               0.0                       0.0   \n",
       "3                     0.0               0.0                       0.0   \n",
       "4                     0.0               0.0                       0.0   \n",
       "\n",
       "  n_wifi_days_2023_6  resource_events_2023_6  n_resource_days_2023_6  \\\n",
       "0                0.0                     0.0                     0.0   \n",
       "1                0.0                     0.0                     0.0   \n",
       "2                0.0                     0.0                     0.0   \n",
       "3                0.0                     0.0                     0.0   \n",
       "4                0.0                     0.0                     0.0   \n",
       "\n",
       "  n_wifi_days_2023_7  \n",
       "0                0.0  \n",
       "1                0.0  \n",
       "2                0.0  \n",
       "3                0.0  \n",
       "4                0.0  \n",
       "\n",
       "[5 rows x 135 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F - Data Cleaning\n",
    "\n",
    "data_cleaned_2 = data2.copy()\n",
    "\n",
    "# Step 1: Drop columns with >90% missingness\n",
    "threshold = 0.90\n",
    "data_cleaned_2 = data_cleaned_2.loc[:, data_cleaned_2.isna().mean() < threshold].copy()\n",
    "\n",
    "# Step 2: Drop rows that are all NA\n",
    "data_cleaned_2 = data_cleaned_2.dropna(axis=0, how='all')\n",
    "\n",
    "# Step 3: Convert comma-based numbers to floats\n",
    "for col in data_cleaned_2.select_dtypes(include='object').columns:\n",
    "    try:\n",
    "        data_cleaned_2[col] = data_cleaned_2[col].str.replace(',', '.').astype(float)\n",
    "    except:\n",
    "        pass  # leave non-numeric columns as object\n",
    "\n",
    "# Step 4: Fill NA with 0 for predetermined count/activity columns\n",
    "fillna_cols = [col for col in data_cleaned_2.columns \n",
    "               if any(x in col for x in ['n_wifi_days', 'resource_events', 'n_resource_days', \n",
    "                                         'pft_', 'actividades', 'total1', 'cred_mat', 'cred_sup'])]\n",
    "\n",
    "for col in fillna_cols:\n",
    "    if pd.api.types.is_numeric_dtype(data_cleaned_2[col]):\n",
    "        data_cleaned_2[col] = data_cleaned_2[col].fillna(0)\n",
    "\n",
    "data_cleaned_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of cleaned dataframe: (159173, 135)\n",
      "\n",
      "Data types:\n",
      "float64    115\n",
      "object      13\n",
      "int64        7\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cleaned dataset saved to: data/02-processed/university_dropout_cleaned_2022.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of cleaned dataframe:\", data_cleaned_2.shape)\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "print(data_cleaned_2.dtypes.value_counts())\n",
    "\n",
    "processed_file_path = os.path.join(PROCESSED_DATA_DIR, 'university_dropout_cleaned_2022.csv')\n",
    "data_cleaned_2.to_csv(processed_file_path, index=False, sep=';')\n",
    "\n",
    "print(f\"\\nCleaned dataset saved to: {processed_file_path}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: REPLACE the contents of this cell with your work, including any updates to recover points lost in your proposal feedback"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: REPLACE the contents of this cell with your work, including any updates to recover points lost in your proposal feedback\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: Replace this with your timeline.  **PLEASE UPDATE your Timeline!** No battle plan survives contact with the enemy, so make sure we understand how your plans have changed.  Also if you have lost points on the previous checkpoint fix them"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
